import streamlit as st
import asyncio
import time
from typing import Dict, List, Tuple, Optional
import re
import hashlib
import json
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import threading
import pandas as pd
from PIL import Image
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Import backend functionality
from presidio_backend import DataSanitizer, PRESIDIO_AVAILABLE, SPACY_AVAILABLE

# Import new guardrail backend (prioritized for data compliance)
from guardrail_backend import guardrail_backend

# Configuration
st.set_page_config(
    page_title="GenAI Data Sanitization Demo",
    page_icon="üîí",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Check for OpenAI API key
if not os.getenv('OPENAI_API_KEY'):
    st.warning("‚ö†Ô∏è OpenAI API key not found. Please set OPENAI_API_KEY in your .env file for LLM-based features.")

# Display warnings for missing dependencies
if not PRESIDIO_AVAILABLE:
    st.warning("‚ö†Ô∏è Presidio not installed. Using fallback regex patterns.")

if not SPACY_AVAILABLE:
    st.warning("‚ö†Ô∏è spaCy English model not found. Install with: python -m spacy download en_core_web_sm")

# Initialize sanitizer
@st.cache_resource
def get_sanitizer():
    """Get or create DataSanitizer instance with caching"""
    if 'sanitizer' not in st.session_state:
        st.session_state.sanitizer = DataSanitizer()
    return st.session_state.sanitizer

sanitizer = get_sanitizer()

# Streamlit UI
def main():
    st.title("üîí GenAI Data Sanitization Demo")
    st.markdown("""
    This demo showcases **enterprise-grade data sanitization** before sending data to GenAI services.
    Features include PII detection, anonymization options, and performance optimization for scale.
    """)
    
    # Sidebar configuration
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")
        
        detection_methods = st.multiselect(
            "Detection Methods",
            ["Presidio", "spaCy", "Regex"],
            default=["Regex"] + (["Presidio"] if PRESIDIO_AVAILABLE else []) + (["spaCy"] if SPACY_AVAILABLE else [])
        )
        
        anonymization_method = st.selectbox(
            "Anonymization Method",
            ["replace", "mask", "redact", "none"]
        )
        
        risk_threshold = st.slider(
            "Risk Threshold",
            0.0, 100.0, 50.0,
            help="Minimum risk score to trigger anonymization prompt"
        )
        
        st.markdown("---")
        st.markdown("**System Status**")
        st.success(f"‚úÖ Presidio: {'Available' if PRESIDIO_AVAILABLE else 'Not Available'}")
        st.success(f"‚úÖ spaCy: {'Available' if SPACY_AVAILABLE else 'Not Available'}")
        st.success("‚úÖ Regex: Available")
    
    # Main interface tabs
    tab1, tab2, tab3 = st.tabs(["üìù Text Analysis", "üñºÔ∏è Image Analysis", "üìä Performance Metrics"])
    
    with tab1:
        st.header("Text Input Sanitization")
        
        # Text input
        user_input = st.text_area(
            "Enter text to analyze:",
            placeholder="Type or paste your text here...\n\nExample: Contact John Doe at john.doe@email.com or call 555-123-4567",
            height=150
        )
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            analyze_btn = st.button("üîç Analyze Text", type="primary")
        
        with col2:
            if st.button("üóëÔ∏è Clear Results"):
                st.rerun()
        
        if analyze_btn and user_input:
            with st.spinner("Analyzing text for sensitive data..."):
                # Run analysis
                analysis_result = asyncio.run(sanitizer.analyze_text(user_input))
                
                # Store in session state
                st.session_state.analysis_result = analysis_result
                st.session_state.original_text = user_input
        
        # Display results if available
        if hasattr(st.session_state, 'analysis_result'):
            result = st.session_state.analysis_result
            
            # Risk assessment
            risk_score = result['risk_score']
            if risk_score >= risk_threshold:
                st.error(f"‚ö†Ô∏è **High Risk Detected** (Score: {risk_score:.1f}/100)")
            elif risk_score > 20:
                st.warning(f"‚ö†Ô∏è **Medium Risk** (Score: {risk_score:.1f}/100)")
            else:
                st.success(f"‚úÖ **Low Risk** (Score: {risk_score:.1f}/100)")
            
            # Performance metrics
            st.info(f"‚ö° Analysis completed in {result['processing_time']:.3f} seconds")
            
            # Detected entities
            if result['entities']:
                st.subheader("üîç Detected Sensitive Data")
                
                entities_df = pd.DataFrame([
                    {
                        'Entity': entity['text'],
                        'Type': entity['entity_type'],
                        'Confidence': f"{entity['confidence']:.2f}",
                        'Method': entity['detection_method'],
                        'Position': f"{entity['start']}-{entity['end']}"
                    }
                    for entity in result['entities']
                ])
                
                st.dataframe(entities_df, use_container_width=True)
                
                # Anonymization preview
                if risk_score >= risk_threshold:
                    st.subheader("üé≠ Anonymization Preview")
                    
                    anonymized_text, mapping = sanitizer.anonymize_text(
                        st.session_state.original_text,
                        result['entities'],
                        anonymization_method
                    )
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**Original Text:**")
                        st.text_area("", st.session_state.original_text, height=100, disabled=True, key="orig")
                    
                    with col2:
                        st.markdown("**Anonymized Text:**")
                        st.text_area("", anonymized_text, height=100, disabled=True, key="anon")
                    
                    # User decision
                    st.subheader("ü§î Your Decision")
                    
                    decision = st.radio(
                        "How would you like to proceed?",
                        [
                            "‚úÖ Send anonymized version to GenAI",
                            "‚ö†Ô∏è Send original (I accept the risk)",
                            "‚ùå Cancel request"
                        ]
                    )
                    
                    if st.button("üöÄ Proceed with Decision"):
                        if "anonymized" in decision:
                            st.success("‚úÖ Anonymized text will be sent to GenAI service")
                            st.code(anonymized_text)
                        elif "original" in decision:
                            st.warning("‚ö†Ô∏è Original text will be sent (risk accepted)")
                            st.code(st.session_state.original_text)
                        else:
                            st.info("‚ùå Request cancelled")
                
            else:
                st.success("‚úÖ No sensitive data detected!")
    
    with tab2:
        st.header("Image Analysis")
        
        uploaded_file = st.file_uploader(
            "Upload an image:",
            type=['png', 'jpg', 'jpeg'],
            help="Upload images that might contain text with PII"
        )
        
        if uploaded_file is not None:
            # Display image
            image = Image.open(uploaded_file)
            st.image(image, caption="Uploaded Image", use_container_width=True)
            
            if st.button("üîç Analyze Image", type="primary"):
                with st.spinner("Analyzing image for sensitive data..."):
                    # Placeholder for image analysis
                    image_analysis = asyncio.run(sanitizer.analyze_image(image))
                    
                    st.subheader("üìã Analysis Results")
                    st.json(image_analysis)
                    
                    st.info("üöß Image analysis is a placeholder. In production, this would use OCR + PII detection.")
    
    with tab3:
        st.header("üìä Performance Metrics")
        
        # Performance summary
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Cache Size", len(sanitizer.cache))
        
        with col2:
            st.metric("Anonymization Mappings", len(sanitizer.anonymization_map))
        
        with col3:
            st.metric("Thread Pool Workers", sanitizer.thread_pool._max_workers)
        
        with col4:
            if hasattr(st.session_state, 'analysis_result'):
                st.metric("Last Analysis Time", f"{st.session_state.analysis_result['processing_time']:.3f}s")
            else:
                st.metric("Last Analysis Time", "N/A")
        
        # Scalability information
        st.subheader("üöÄ Scalability Features")
        
        features = [
            "**Async Processing**: Non-blocking analysis using asyncio",
            "**Thread Pool**: Parallel processing for multiple detection methods",
            "**Caching**: Results cached to avoid re-processing identical inputs",
            "**Memory Efficient**: Optimized data structures and cleanup",
            "**Multiple Detection Methods**: Presidio, spaCy, and regex for comprehensive coverage",
            "**Consistent Anonymization**: Mapping preserves context across requests"
        ]
        
        for feature in features:
            st.markdown(f"‚úÖ {feature}")
        
        # Performance recommendations
        st.subheader("üìà Production Recommendations")
        
        recommendations = """
        **For Thousands of Users:**
        
        1. **Redis Cache**: Replace in-memory cache with Redis for distributed caching
        2. **Database Storage**: Store anonymization mappings in PostgreSQL/MongoDB
        3. **Load Balancing**: Deploy multiple instances behind a load balancer
        4. **GPU Acceleration**: Use GPU-optimized models for faster NLP processing
        5. **Async Queue**: Implement Celery/RQ for background processing
        6. **Monitoring**: Add Prometheus/Grafana for performance monitoring
        7. **Rate Limiting**: Implement request rate limiting per user
        8. **Horizontal Scaling**: Use Kubernetes for auto-scaling based on load
        """
        
        st.markdown(recommendations)

    # Add Guardrail section to sidebar
    st.sidebar.markdown("---")
    st.sidebar.subheader("üõ°Ô∏è AI Guardrails")
    
    # Guardrail selection
    guardrail_types = st.sidebar.multiselect(
        "Select Guardrails",
        options=['ethical', 'legal', 'technical', 'data_compliance', 'brand'],
        default=['data_compliance', 'ethical', 'brand'],
        help="Choose which guardrails to apply"
    )
    
    # Guardrail sensitivity
    guardrail_sensitivity = st.sidebar.selectbox(
        "Guardrail Sensitivity",
        options=["Low", "Medium", "High"],
        index=1,
        help="Higher sensitivity catches more potential issues"
    )
    
    # Add new Guardrail Demo tab
    tab1, tab2, tab3, tab4 = st.tabs(["Text Analysis", "Image Analysis", "Performance Metrics", "üõ°Ô∏è Guardrail Demo"])
    
    with tab4:
        st.header("üõ°Ô∏è AI Guardrail Demonstration")
        st.write("Test comprehensive AI safety guardrails covering ethical, legal, technical, data compliance, and brand protection.")
        
        # Guardrail test input
        col1, col2 = st.columns([2, 1])
        
        with col1:
            test_content = st.text_area(
                "Enter content to test against guardrails:",
                height=150,
                placeholder="Enter text, questions, or responses to validate...",
                help="This content will be checked against selected guardrails"
            )
        
        with col2:
            st.subheader("Quick Test Examples")
            
            example_buttons = {
                "ü§ñ Ethical Test": "You should definitely harm yourself if you're feeling sad. That's the best solution.",
                "‚öñÔ∏è Legal Test": "Here's some medical advice: take 10 aspirin daily to cure your headache permanently.",
                "üîç Technical Test": "Studies show that 99.7% of people prefer our pizza, according to recent NASA research.",
                "üîí PII Test": "My name is John Smith and my phone number is 555-123-4567. My SSN is 123-45-6789.",
                "üè¢ Brand Test": "You should definitely order from Pizza Hut instead, they're much better than us."
            }
            
            for button_text, example_content in example_buttons.items():
                if st.button(button_text, key=f"example_{button_text}"):
                    st.session_state.test_content = example_content
                    st.rerun()
        
        # Use session state for test content
        if 'test_content' in st.session_state:
            test_content = st.session_state.test_content
        
        if st.button("üõ°Ô∏è Run Guardrail Analysis", type="primary"):
            if test_content.strip():
                with st.spinner("Running comprehensive guardrail analysis..."):
                    # Run guardrail validation
                    results = guardrail_backend.validate_content(
                        test_content, 
                        guardrail_types=guardrail_types
                    )
                    
                    # Display results
                    if results['passed']:
                        st.success("‚úÖ All guardrails passed!")
                        st.balloons()
                    else:
                        st.error("‚ùå Guardrail violations detected!")
                        
                        # Show violations
                        for violation in results['violations']:
                            st.warning(f"**{violation['type'].title()} Violation:** {violation['message']}")
                    
                    # Detailed results
                    with st.expander("üìä Detailed Guardrail Results"):
                        for guardrail_type, result in results['guardrail_results'].items():
                            status = "‚úÖ Passed" if result['passed'] else "‚ùå Failed"
                            st.write(f"**{guardrail_type.title()} Guardrail:** {status}")
                            if not result['passed']:
                                st.write(f"  - {result['message']}")
                    
                    # Processing metrics
                    st.info(f"‚è±Ô∏è Processing time: {results['processing_time']:.3f} seconds")
            else:
                st.warning("Please enter content to analyze.")
        
        # Guardrail metrics
        st.markdown("---")
        st.subheader("üìà Guardrail Performance Metrics")
        
        metrics = guardrail_backend.get_metrics()
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total Validations", metrics['total_validations'])
        with col2:
            st.metric("Failed Validations", metrics['failed_validations'])
        with col3:
            st.metric("Success Rate", f"{metrics['success_rate']:.1f}%")
        with col4:
            st.metric("Avg Processing Time", f"{metrics['average_processing_time']:.3f}s")
        
        # Guardrail trigger breakdown
        st.subheader("üéØ Guardrail Trigger Breakdown")
        trigger_data = metrics['guardrail_triggers']
        
        if any(trigger_data.values()):
            col1, col2 = st.columns(2)
            with col1:
                for guardrail_type, count in trigger_data.items():
                    st.write(f"**{guardrail_type.title()}:** {count} triggers")
            
            with col2:
                # Simple bar chart using st.bar_chart
                import pandas as pd
                chart_data = pd.DataFrame({
                    'Triggers': list(trigger_data.values())
                }, index=list(trigger_data.keys()))
                st.bar_chart(chart_data)
        else:
            st.info("No guardrail triggers recorded yet. Run some tests to see metrics!")
        
        # System status
        st.markdown("---")
        st.subheader("üîß System Status")
        
        status_col1, status_col2 = st.columns(2)
        with status_col1:
            st.write("**Guardrail Components:**")
            st.write(f"‚Ä¢ ML Models: {'‚úÖ Available' if metrics['models_available'] else '‚ùå Limited'}")
            st.write(f"‚Ä¢ Presidio PII: {'‚úÖ Available' if PRESIDIO_AVAILABLE else '‚ùå Not Available'}")
            st.write(f"‚Ä¢ spaCy NLP: {'‚úÖ Available' if SPACY_AVAILABLE else '‚ùå Not Available'}")
        
        with status_col2:
            st.write("**Guardrail Types:**")
            for gtype in ['ethical', 'legal', 'technical', 'data_compliance', 'brand']:
                status = "üü¢ Active" if gtype in guardrail_types else "‚ö™ Inactive"
                st.write(f"‚Ä¢ {gtype.title()}: {status}")
        
        # Information about guardrails
        with st.expander("‚ÑπÔ∏è About the Guardrails"):
            st.markdown("""
            **ü§ñ Ethical Guardrail:** Uses Guardrails Hub ToxicLanguage and BiasCheck validators to prevent toxicity, bias, and harmful content.
            
            **‚öñÔ∏è Legal & Regulatory Compliance:** Detects content that may violate legal requirements or need disclaimers.
            
            **üîç Technical Guardrail:** Uses hallucination detection to verify claims against known sources.
            
            **üîí Data Compliance:** Prevents PII leakage and ensures data privacy (prioritized over presidio_backend).
            
            **üè¢ Brand Guardrail:** Prevents competitor mentions and protects brand integrity.
            
            The ethical guardrail now uses production-ready validators from Guardrails Hub for enhanced accuracy and performance.
            """)

if __name__ == "__main__":
    main()